import random  # <--- 1. å¼•å…¥éšæœºåº“ï¼Œç”¨äºæ‰“ç ´æ¨èçš„é‡å¤æ€§
import streamlit as st
import pandas as pd
import json
import os
from dotenv import load_dotenv
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- 0. é—¨å«ç³»ç»Ÿ ---
def check_access():
    if "authenticated" not in st.session_state:
        st.session_state.authenticated = False

    if st.session_state.authenticated:
        return True

    st.title("ğŸ”’ è¿™æ˜¯ä¸€ä¸ªç§å¯†åº”ç”¨")
    st.write("è¯·åœ¨ä¸‹æ–¹è¾“å…¥é‚€è¯·ç ä»¥ç»§ç»­è®¿é—®ã€‚")
    
    user_input = st.text_input("è¯·è¾“å…¥é‚€è¯·ç  (Access Key)", type="password")
    
    if st.button("è§£é”è¿›å…¥"):
        valid_keys = st.secrets.get("access_keys", [])
        if user_input in valid_keys:
            st.session_state.authenticated = True
            st.success("âœ… éªŒè¯æˆåŠŸï¼æ­£åœ¨åŠ è½½...")
            st.rerun()
        else:
            st.error("âŒ é‚€è¯·ç æ— æ•ˆ")
    return False

if not check_access():
    st.stop()

# --- 1. é…ç½®åŠ è½½ ---
if "OPENAI_API_KEY" in st.secrets:
    API_KEY = st.secrets["OPENAI_API_KEY"]
    BASE_URL = st.secrets["OPENAI_BASE_URL"]
    MODEL_NAME = st.secrets["OPENAI_MODEL_NAME"]
else:
    load_dotenv()
    API_KEY = os.getenv("OPENAI_API_KEY")
    BASE_URL = os.getenv("OPENAI_BASE_URL")
    MODEL_NAME = os.getenv("OPENAI_MODEL_NAME")

if not API_KEY:
    st.error("âŒ æœªé…ç½® API Key")
    st.stop()

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

# ğŸ”´ 2. è¿™é‡Œçš„æ•°æ®åº“æ–‡ä»¶å¿…é¡»æ˜¯ç¿»è¯‘å¥½çš„ä¸­æ–‡ç‰ˆ
DATA_FILE = "punch_recipes_cn.jsonl"

st.set_page_config(page_title="Punch AI è°ƒé…’å¸ˆ", page_icon="ğŸ¸", layout="wide") 

# --- 2. æ•°æ®åŠ è½½ä¸å‘é‡åŒ– ---
@st.cache_resource
def load_data_and_vectors():
    data = []
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line))
    except FileNotFoundError:
        return None, None, None

    df = pd.DataFrame(data)

    # æ··åˆæ–‡æœ¬ç”¨äºæœç´¢ (åŒ…å«æ ‡é¢˜ã€åŸæ–™ã€æ ‡ç­¾)
    df['combined_text'] = (
        df['title'].fillna('') + " " + 
        df['ingredients'].astype(str) + " " + 
        df['tags'].astype(str)
    )

    # ä½¿ç”¨å­—ç¬¦çº§ n-gram å®ç°æ¨¡ç³ŠåŒ¹é…
    # å³ä½¿æ•°æ®åº“æ˜¯ä¸­æ–‡ï¼Œä¿ç•™è¿™ä¸ªè®¾ç½®ä¹Ÿèƒ½å¾ˆå¥½åœ°åŒ¹é…è‹±æ–‡é…’å
    vectorizer = TfidfVectorizer(
        stop_words='english',
        analyzer='char_wb', 
        ngram_range=(3, 5),
        max_features=5000 # é™åˆ¶ç‰¹å¾æ•°é‡ï¼Œé˜²æ­¢åŠ è½½è¿‡æ…¢
    )
    
    tfidf_matrix = vectorizer.fit_transform(df['combined_text'])

    return df, vectorizer, tfidf_matrix

df, vectorizer, tfidf_matrix = load_data_and_vectors()

if df is None:
    st.error(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ {DATA_FILE}")
    st.stop()

# --- 3. æ ¸å¿ƒ AI é€»è¾‘ (å·²åŠ å…¥â€œé±¼å¡˜æ‰©å®¹â€é€»è¾‘) ---
def get_ai_recommendation(user_query):
    # === A. æ£€ç´¢ ===
    try:
        user_vec = vectorizer.transform([user_query])
        similarities = cosine_similarity(user_vec, tfidf_matrix).flatten()
        
        # ğŸ”´ 3. æ‰©å¤§å€™é€‰æ±  (é±¼å¡˜é€»è¾‘)
        # å–å‰ 100 ä¸ªç›¸å…³çš„ç»“æœ
        top_k = 100 
        top_indices = similarities.argsort()[-top_k:][::-1]
        
        # ğŸ”´ 4. éšæœºæ´—ç‰Œ (Shuffling)
        # ä»è¿™ 100 ä¸ªé‡ŒéšæœºæŠ½ 20 ä¸ªï¼Œæ‰“ç ´â€œæ€»æ˜¯æ¨èç¬¬ä¸€åâ€çš„é­”å’’
        candidates_pool = top_indices.tolist()
        
        if len(candidates_pool) > 20:
            selected_indices = random.sample(candidates_pool, 20)
        else:
            selected_indices = candidates_pool
            
        candidates = df.iloc[selected_indices]

    except Exception as e:
        return f"æ£€ç´¢ç³»ç»Ÿå‡ºé”™äº†: {e}", pd.DataFrame()

    # === B. å¢å¼º (æ„å»º Context) ===
    context_text = ""
    for idx, row in candidates.iterrows():
        # ç›´æ¥è¯»å–ä¸­æ–‡æ•°æ®
        context_text += f"""
        [é…’å: {row['title']}]
        [åŸæ–™: {row['ingredients']}]
        [æ­¥éª¤: {row['instructions']}]
        [ç®€ä»‹: {row.get('intro_philosophy', '')[:100]}]
        ---
        """

    # === C. ç”Ÿæˆ (Prompt) ===
    combined_prompt = f"""
    ã€è§’è‰²è®¾å®šã€‘
    ä½ æ˜¯ä¸€ä½è§å¤šè¯†å¹¿çš„è°ƒé…’å¸ˆï¼Œæ“…é•¿å‘æ˜å†·é—¨ä½³é…¿ã€‚
    
    ã€ä»»åŠ¡ã€‘
    ç”¨æˆ·æƒ³å–ï¼š"{user_query}"
    ä»ä¸‹é¢çš„ã€å€™é€‰é…’å•ã€‘ä¸­ï¼ŒæŒ‘é€‰ 3 æ¬¾æ¨èç»™ç”¨æˆ·ã€‚
    
    ã€ç­–ç•¥è¦æ±‚ã€‘
    1. **ä¸è¦æ€»æ˜¯æ¨èæœ€å¸¸è§çš„é…’**ã€‚å¦‚æœå€™é€‰åå•é‡Œæœ‰ç‹¬ç‰¹ã€å†·é—¨ä½†ç¬¦åˆç”¨æˆ·å£å‘³çš„é…æ–¹ï¼Œä¼˜å…ˆæ¨èå®ƒä»¬ï¼Œç»™ç”¨æˆ·æƒŠå–œã€‚
    2. å¦‚æœæœ‰å¤šç§åŸºé…’é€‰æ‹©ï¼Œè¯·å±•ç¤ºå¤šæ ·æ€§ã€‚
    3. åŸºäºæä¾›çš„æ•°æ®ç›´æ¥å›ç­”ï¼Œå› ä¸ºæ•°æ®å·²ç»æ˜¯ä¸­æ–‡çš„äº†ã€‚
    
    ã€å€™é€‰é…’å•ã€‘
    {context_text}

    ã€å›å¤æ ¼å¼ã€‘
    ### ğŸ¸ [é…’å] (ä¿æŒè‹±æ–‡åŸå)
    - **æ¨èç†ç”±**: ...
    - **åŸæ–™**: ...
    - **æ­¥éª¤**: ...
    """

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME, 
            messages=[{"role": "user", "content": combined_prompt}],
            temperature=0.8, 
            max_tokens=4096, 
            presence_penalty=0.6 
        )
        if not response.choices:
            return f"âš ï¸ API è¿”å›ç©ºç»“æœã€‚", candidates
        return response.choices[0].message.content, candidates

    except Exception as e:
        return f"âŒ AI è¿æ¥æŠ¥é”™: {str(e)}", pd.DataFrame()

# ==========================================
# ğŸ¨ ç•Œé¢å¸ƒå±€å¼€å§‹
# ==========================================

st.title("ğŸ¸ Punch AI è°ƒé…’å¸ˆ")

# --- ğŸ” ä¾§è¾¹æ ï¼šé…æ–¹ç™¾ç§‘ (æ— ç¿»è¯‘æ¨¡å—ï¼Œç›´æ¥æ˜¾ç¤º) ---
with st.sidebar:
    st.header("ğŸ“– é…æ–¹ç™¾ç§‘å…¨ä¹¦")
    search_query = st.text_input("ğŸ” æœç´¢é…æ–¹ (æ”¯æŒæ¨¡ç³Šæ‹¼å†™)", placeholder="ä¾‹å¦‚: Bronx")
    
    selected_recipe_id = None
    
    if search_query:
        search_vec = vectorizer.transform([search_query])
        sims = cosine_similarity(search_vec, tfidf_matrix).flatten()
        
        # æ‰¾å‡ºæœ€ç›¸ä¼¼çš„ 10 ä¸ª
        top_indices = sims.argsort()[-10:][::-1]
        
        options_map = {}
        for i in top_indices:
            row = df.iloc[i]
            if sims[i] > 0.1:
                options_map[f"{row['title']}"] = i
        
        if options_map:
            st.success(f"æ‰¾åˆ° {len(options_map)} ä¸ªç›¸å…³ç»“æœ:")
            selected_name = st.selectbox("ğŸ‘‡ ç‚¹å‡»é€‰æ‹©æŸ¥çœ‹è¯¦æƒ…:", list(options_map.keys()))
            
            if selected_name:
                selected_recipe_id = options_map[selected_name]
        else:
            st.warning("ğŸ¤” æœªæ‰¾åˆ°ç›¸ä¼¼é…æ–¹")

# ==========================================
# ğŸ“‹ ä¸»ç•Œé¢ï¼šé…æ–¹è¯¦æƒ…å¡ç‰‡ (é™æ€æ˜¾ç¤ºï¼Œæ— éœ€AIç¿»è¯‘)
# ==========================================
if selected_recipe_id is not None:
    # ğŸ”´ 5. ç›´æ¥è¯»å–æ•°æ®åº“é‡Œçš„ä¸­æ–‡æ•°æ®
    recipe_data = df.iloc[selected_recipe_id]
    
    with st.container(border=True):
        col_close, col_title = st.columns([1, 9])
        
        # å…³é—­æŒ‰é’®
        with col_close:
            if st.button("âŒ", key="close_btn"):
                selected_recipe_id = None
                st.rerun()

        with col_title:
            st.header(f"ğŸ¹ {recipe_data['title']}") # æ ‡é¢˜ä¿æŒè‹±æ–‡
        
        # ç®€ä»‹ (æ•°æ®åº“é‡Œå·²ç»æ˜¯ä¸­æ–‡äº†)
        st.info(f"ğŸ’¡ {recipe_data.get('intro_philosophy', 'æš‚æ— ç®€ä»‹')}")
        
        c1, c2 = st.columns(2)
        with c1:
            st.subheader("ğŸ§‚ åŸæ–™ Ingredients")
            # å…¼å®¹å¤„ç†ï¼šå¦‚æœæ˜¯åˆ—è¡¨ç›´æ¥æ˜¾ç¤ºï¼Œå¦‚æœæ˜¯å­—ç¬¦ä¸²åˆ™ç›´æ¥æ˜¾ç¤º
            ings = recipe_data['ingredients']
            if isinstance(ings, list):
                for ing in ings:
                    st.write(f"â€¢ {ing}")
            else:
                st.write(ings)
                    
        with c2:
            st.subheader("ğŸ¥£ åšæ³• Instructions")
            st.write(recipe_data['instructions'])
            
        st.caption(f"æ ‡ç­¾: {recipe_data.get('tags', 'Classic')}")
        
    st.markdown("---") 

# --- ğŸ’¬ èŠå¤©åŒºåŸŸ ---
st.caption(f"ç§äººå®šåˆ¶ Â· {MODEL_NAME}")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„ AI ä¾é…’å¸ˆã€‚æ‚¨å¯ä»¥ç›´æ¥ç‚¹é¤ï¼Œæˆ–è€…åœ¨å·¦ä¾§æŸ¥é˜…é…æ–¹ã€‚"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("ä»Šå¤©æƒ³å–ç‚¹ä»€ä¹ˆé£å‘³çš„ï¼Ÿ"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨é…æ–¹åº“ä¸­æœå¯»..."):
            ai_reply, related = get_ai_recommendation(prompt)
            st.markdown(ai_reply)
    st.session_state.messages.append({"role": "assistant", "content": ai_reply})