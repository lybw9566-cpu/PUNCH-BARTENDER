import random  # <--- åˆ«å¿˜äº†åœ¨æ–‡ä»¶æœ€é¡¶éƒ¨çš„ import åŒºåŸŸåŠ ä¸Šè¿™å¥
import streamlit as st
import pandas as pd
import json
import os
from dotenv import load_dotenv
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# --- 0. é—¨å«ç³»ç»Ÿ ---
def check_access():
    if "authenticated" not in st.session_state:
        st.session_state.authenticated = False

    if st.session_state.authenticated:
        return True

    st.title("ğŸ”’ è¿™æ˜¯ä¸€ä¸ªç§å¯†åº”ç”¨")
    st.write("è¯·åœ¨ä¸‹æ–¹è¾“å…¥é‚€è¯·ç ä»¥ç»§ç»­è®¿é—®ã€‚")
    
    user_input = st.text_input("è¯·è¾“å…¥é‚€è¯·ç  (Access Key)", type="password")
    
    if st.button("è§£é”è¿›å…¥"):
        valid_keys = st.secrets.get("access_keys", [])
        if user_input in valid_keys:
            st.session_state.authenticated = True
            st.success("âœ… éªŒè¯æˆåŠŸï¼æ­£åœ¨åŠ è½½...")
            st.rerun()
        else:
            st.error("âŒ é‚€è¯·ç æ— æ•ˆ")
    return False

if not check_access():
    st.stop()

# --- 1. é…ç½®åŠ è½½ ---
if "OPENAI_API_KEY" in st.secrets:
    API_KEY = st.secrets["OPENAI_API_KEY"]
    BASE_URL = st.secrets["OPENAI_BASE_URL"]
    MODEL_NAME = st.secrets["OPENAI_MODEL_NAME"]
else:
    load_dotenv()
    API_KEY = os.getenv("OPENAI_API_KEY")
    BASE_URL = os.getenv("OPENAI_BASE_URL")
    MODEL_NAME = os.getenv("OPENAI_MODEL_NAME")

if not API_KEY:
    st.error("âŒ æœªé…ç½® API Key")
    st.stop()

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
DATA_FILE = "punch_recipes.jsonl"

st.set_page_config(page_title="Punch AI è°ƒé…’å¸ˆ", page_icon="ğŸ¸", layout="wide") 
# æ³¨æ„ï¼šlayout æ”¹ä¸º 'wide' å¯ä»¥è®©ä¾§è¾¹æ å’Œä¸»å†…å®¹æ›´å®½æ•

# --- 2. æ•°æ®åŠ è½½ä¸å‘é‡åŒ– (ä¿æŒ char_wb æ¨¡ç³Šæœç´¢) ---
@st.cache_resource
def load_data_and_vectors():
    data = []
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line))
    except FileNotFoundError:
        return None, None, None

    df = pd.DataFrame(data)

    # æ··åˆæ–‡æœ¬ç”¨äºæœç´¢
    df['combined_text'] = (
        df['title'].fillna('') + " " + 
        df['ingredients'].astype(str) + " " + 
        df['tags'].astype(str)
    )

    # ä½¿ç”¨å­—ç¬¦çº§ n-gram å®ç°æ¨¡ç³ŠåŒ¹é…
    vectorizer = TfidfVectorizer(
        stop_words='english',
        analyzer='char_wb', 
        ngram_range=(3, 5)
    )
    
    tfidf_matrix = vectorizer.fit_transform(df['combined_text'])

    return df, vectorizer, tfidf_matrix

df, vectorizer, tfidf_matrix = load_data_and_vectors()

if df is None:
    st.error(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ {DATA_FILE}")
    st.stop()

# --- 3. æ ¸å¿ƒ AI é€»è¾‘ (å‡çº§ç‰ˆï¼šå¢åŠ éšæœºå¤šæ ·æ€§) ---
def get_ai_recommendation(user_query):
    # === A. æ£€ç´¢ ===
    try:
        user_vec = vectorizer.transform([user_query])
        similarities = cosine_similarity(user_vec, tfidf_matrix).flatten()
        
        # ğŸ”´ å…³é”®ä¿®æ”¹ 1: æ‰©å¤§å€™é€‰æ±  (é±¼å¡˜)
        # ä»¥å‰æˆ‘ä»¬åªå–å‰ 30 (argsort()[-30:])ï¼Œå®ƒä»¬æ°¸è¿œæ˜¯å›ºå®šçš„ã€‚
        # ç°åœ¨æˆ‘ä»¬å–å‰ 100 ä¸ªï¼Œè¿™äº›éƒ½æ˜¯ç›¸å…³æ€§ä¸é”™çš„é…’ã€‚
        top_k = 100 
        
        # è·å–å‰ 100 åçš„ç´¢å¼• (ä»ä½åˆ°é«˜ï¼Œæ‰€ä»¥åé¢è¦åˆ‡ç‰‡)
        top_indices = similarities.argsort()[-top_k:][::-1]
        
        # ğŸ”´ å…³é”®ä¿®æ”¹ 2: éšæœºæ´—ç‰Œ (Shuffling)
        # å°†è¿™ top_indices è½¬ä¸ºåˆ—è¡¨
        candidates_pool = top_indices.tolist()
        
        # ä»è¿™ 100 ä¸ªé‡Œï¼ŒéšæœºæŠ½å– 20 ä¸ªç»™ AI
        # è¿™æ ·æ—¢ä¿è¯äº†ç›¸å…³æ€§(éƒ½åœ¨å‰100)ï¼Œåˆä¿è¯äº†æ¯æ¬¡ä¸ä¸€æ ·
        if len(candidates_pool) > 20:
            selected_indices = random.sample(candidates_pool, 20)
        else:
            selected_indices = candidates_pool
            
        candidates = df.iloc[selected_indices]

    except Exception as e:
        return f"æ£€ç´¢ç³»ç»Ÿå‡ºé”™äº†: {e}", pd.DataFrame()

    # === B. å¢å¼º (æ„å»º Context) ===
    context_text = ""
    for idx, row in candidates.iterrows():
        # è¿™é‡Œé€‚é…äº†ä¸­æ–‡æ•°æ®åº“çš„å­—æ®µï¼Œå¦‚æœæ˜¯è‹±æ–‡ç‰ˆä¼šè‡ªåŠ¨æ˜¾ç¤ºè‹±æ–‡
        context_text += f"""
        [é…’å: {row['title']}]
        [åŸæ–™: {row['ingredients']}]
        [æ­¥éª¤: {row['instructions']}]
        [ç®€ä»‹: {row.get('intro_philosophy', '')[:100]}]
        ---
        """

    # === C. ç”Ÿæˆ (Prompt) ===
    combined_prompt = f"""
    ã€è§’è‰²è®¾å®šã€‘
    ä½ æ˜¯ä¸€ä½è§å¤šè¯†å¹¿çš„è°ƒé…’å¸ˆï¼Œæ“…é•¿å‘æ˜å†·é—¨ä½³é…¿ã€‚
    
    ã€ä»»åŠ¡ã€‘
    ç”¨æˆ·æƒ³å–ï¼š"{user_query}"
    ä»ä¸‹é¢çš„ã€å€™é€‰é…’å•ã€‘ä¸­ï¼ŒæŒ‘é€‰ 3 æ¬¾æ¨èç»™ç”¨æˆ·ã€‚
    
    ã€ç­–ç•¥è¦æ±‚ã€‘
    1. **ä¸è¦æ€»æ˜¯æ¨èæœ€å¸¸è§çš„é…’**ã€‚å¦‚æœå€™é€‰åå•é‡Œæœ‰ç‹¬ç‰¹ã€å†·é—¨ä½†ç¬¦åˆç”¨æˆ·å£å‘³çš„é…æ–¹ï¼Œä¼˜å…ˆæ¨èå®ƒä»¬ï¼Œç»™ç”¨æˆ·æƒŠå–œã€‚
    2. å¦‚æœæœ‰å¤šç§åŸºé…’é€‰æ‹©ï¼ˆå¦‚æ—¢æœ‰é‡‘é…’åˆæœ‰ä¼ç‰¹åŠ ï¼‰ï¼Œè¯·å±•ç¤ºå¤šæ ·æ€§ã€‚
    
    ã€å€™é€‰é…’å•ã€‘
    {context_text}

    ã€å›å¤æ ¼å¼ã€‘
    è¯·ç”¨ä¼˜é›…çš„ä¸­æ–‡å›å¤ã€‚
    ### ğŸ¸ [é…’å]
    - **æ¨èç†ç”±**: ...
    - **åŸæ–™**: ...
    - **æ­¥éª¤**: ...
    """

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME, 
            messages=[{"role": "user", "content": combined_prompt}],
            temperature=0.8, # ç¨å¾®è°ƒé«˜æ¸©åº¦ï¼Œè®© AI è¯´è¯æ›´æœ‰åˆ›é€ åŠ›
            max_tokens=4096, 
            presence_penalty=0.6 # æƒ©ç½šé‡å¤å†…å®¹
        )
        if not response.choices:
            return f"âš ï¸ API è¿”å›ç©ºç»“æœã€‚", candidates
        return response.choices[0].message.content, candidates

    except Exception as e:
        return f"âŒ AI è¿æ¥æŠ¥é”™: {str(e)}", pd.DataFrame()
# ==========================================
# ğŸ¨ ç•Œé¢å¸ƒå±€å¼€å§‹
# ==========================================

st.title("ğŸ¸ Punch AI è°ƒé…’å¸ˆ")

# --- ğŸ” ä¾§è¾¹æ ï¼šè¶…çº§æ¨¡ç³Šæœç´¢ ---
with st.sidebar:
    st.header("ğŸ“– é…æ–¹ç™¾ç§‘å…¨ä¹¦")
    # 1. æœç´¢æ¡†
    search_query = st.text_input("ğŸ” æœç´¢é…æ–¹ (æ”¯æŒæ¨¡ç³Šæ‹¼å†™)", placeholder="ä¾‹å¦‚: Bronx æˆ– margrita")
    
    selected_recipe_id = None
    
    if search_query:
        # å¤ç”¨é‚£ä¸ªå¼ºå¤§çš„å‘é‡æœç´¢å¼•æ“
        # å³ä½¿ä½ è¾“é”™ "Mrgarita"ï¼Œå®ƒä¹Ÿèƒ½ç®—å‡ºå®ƒæ˜¯ Margarita
        search_vec = vectorizer.transform([search_query])
        sims = cosine_similarity(search_vec, tfidf_matrix).flatten()
        
        # æ‰¾å‡ºæœ€ç›¸ä¼¼çš„ 10 ä¸ª
        top_indices = sims.argsort()[-10:][::-1]
        
        # åˆ¶ä½œä¸‹æ‹‰èœå•é€‰é¡¹å­—å…¸: { "é…’å": ID }
        options_map = {}
        for i in top_indices:
            row = df.iloc[i]
            # å¦‚æœç›¸ä¼¼åº¦å¤ªä½(å°äº0.1)ï¼Œå¯èƒ½æ˜¯å™ªéŸ³ï¼Œä¸æ˜¾ç¤º
            if sims[i] > 0.1:
                options_map[f"{row['title']}"] = i
        
        if options_map:
            st.success(f"æ‰¾åˆ° {len(options_map)} ä¸ªç›¸å…³ç»“æœ:")
            # 2. ä¸‹æ‹‰é€‰æ‹©æ¡†
            selected_name = st.selectbox("ğŸ‘‡ ç‚¹å‡»é€‰æ‹©æŸ¥çœ‹è¯¦æƒ…:", list(options_map.keys()))
            
            if selected_name:
                selected_recipe_id = options_map[selected_name]
        else:
            st.warning("ğŸ¤” æœªæ‰¾åˆ°ç›¸ä¼¼é…æ–¹ï¼Œè¯·æ¢ä¸ªè¯è¯•è¯•")

# ==========================================
# ğŸ“‹ ä¸»ç•Œé¢ï¼šæ™ºèƒ½ç¿»è¯‘é…æ–¹å¡ç‰‡
# ==========================================
if selected_recipe_id is not None:
    # 1. è·å–åŸå§‹è‹±æ–‡æ•°æ®
    raw_data = df.iloc[selected_recipe_id]
    
    # 2. æ„å»ºç¿»è¯‘è¯·æ±‚ Prompt
    translation_prompt = f"""
    ã€ä»»åŠ¡ã€‘
    è¯·å°†ä»¥ä¸‹é¸¡å°¾é…’é…æ–¹ç¿»è¯‘æˆä¸­æ–‡ï¼Œå¹¶æŒ‰ç…§ Markdown æ ¼å¼æ’ç‰ˆã€‚
    
    ã€åŸå§‹æ•°æ®ã€‘
    Name: {raw_data['title']}
    Intro: {raw_data['intro_philosophy']}
    Ingredients: {raw_data['ingredients']}
    Instructions: {raw_data['instructions']}
    Tags: {raw_data.get('tags', '')}

    ã€è¦æ±‚ã€‘
    1. æ ‡é¢˜ç”¨ H2 (##) åŠ  emojiã€‚
    2. ç®€ä»‹ç”¨å¼•ç”¨æ ¼å¼ (>)ã€‚
    3. åŸæ–™ç”¨åˆ—è¡¨ï¼Œä¿ç•™åŸå§‹ç”¨é‡ï¼ˆå¦‚ 2 ozï¼‰ï¼Œä½†åœ¨æ‹¬å·é‡Œä¼°ç®— ml æ•°ï¼ˆ1 oz â‰ˆ 30mlï¼‰ã€‚
    4. æ­¥éª¤å¿…é¡»æ¸…æ™°æ˜“æ‡‚ã€‚
    5. è¯­æ°”ï¼šåƒä¸€ä½ä¼˜é›…çš„è°ƒé…’å¸ˆåœ¨ä»‹ç»ã€‚
    """

    # 3. æ˜¾ç¤ºåŠ è½½åŠ¨ç”»å¹¶è°ƒç”¨ AI
    with st.container(border=True):
        # å¦‚æœç”¨æˆ·é¢‘ç¹ç‚¹å‡»ï¼Œæ¯æ¬¡éƒ½ç¿»è¯‘æœ‰ç‚¹æµªè´¹ï¼Œä½†åœ¨ Streamlit é‡Œè¿™æ˜¯æœ€ç®€å•çš„å†™æ³•
        # å¦‚æœä½ ä»‹æ„é€Ÿåº¦ï¼Œå¯ä»¥ä½¿ç”¨ @st.cache_data ç¼“å­˜ç¿»è¯‘ç»“æœ
        
        with st.spinner(f"æ­£åœ¨å°† {raw_data['title']} ç¿»è¯‘ä¸ºä¸­æ–‡..."):
            try:
                trans_response = client.chat.completions.create(
                    model=MODEL_NAME, # ä½¿ç”¨ gpt-4o-mini é€Ÿåº¦æå¿«
                    messages=[{"role": "user", "content": translation_prompt}],
                    temperature=0.3, # ç¿»è¯‘éœ€è¦å‡†ç¡®ï¼Œæ¸©åº¦è°ƒä½
                    max_tokens=2000
                )
                translated_content = trans_response.choices[0].message.content
                
                # 4. å±•ç¤ºç¿»è¯‘åçš„ç»“æœ
                # å…³é—­æŒ‰é’® (å…¶å®åªæ˜¯æ¸…ç©ºé€‰ä¸­çŠ¶æ€ï¼Œä½†åœ¨ Streamlit éœ€è¦é‡æ–°åŠ è½½)
                col1, col2 = st.columns([9, 1])
                with col2:
                    if st.button("âŒ", help("å…³é—­å¡ç‰‡")):
                        selected_recipe_id = None
                        st.rerun()
                
                # æ¸²æŸ“ AI å†™å¥½çš„ Markdown
                st.markdown(translated_content)
                
                # 5. åœ¨åº•éƒ¨æ˜¾ç¤ºåŸå§‹è‹±æ–‡ï¼ˆæŠ˜å ï¼‰ï¼Œæ–¹ä¾¿æ ¸å¯¹
                with st.expander("ğŸ” æŸ¥çœ‹åŸå§‹è‹±æ–‡é…æ–¹ (Original Recipe)"):
                    st.write(raw_data.to_dict())
                    
            except Exception as e:
                st.error(f"ç¿»è¯‘æœåŠ¡å¼€å°å·®äº†: {e}")
                # å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œå…œåº•æ˜¾ç¤ºè‹±æ–‡
                st.write(raw_data)

    st.markdown("---") # åˆ†å‰²çº¿

# --- ğŸ’¬ èŠå¤©åŒºåŸŸ (AI è°ƒé…’å¸ˆ) ---
st.caption(f"ç§äººå®šåˆ¶ Â· {MODEL_NAME}")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "æ‚¨å¥½ï¼æ‚¨å¯ä»¥åœ¨å·¦ä¾§æœç´¢ç‰¹å®šçš„é…æ–¹å¡ç‰‡ï¼Œä¹Ÿå¯ä»¥ç›´æ¥åœ¨è¿™é‡Œå‘Šè¯‰æˆ‘æ‚¨çš„å£å‘³ï¼Œè®©æˆ‘ä¸ºæ‚¨æ¨èã€‚"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("æè¿°æ‚¨çš„å£å‘³ï¼Œæˆ–è®© AI æ¨è..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    with st.chat_message("assistant"):
        with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
            ai_reply, related = get_ai_recommendation(prompt)
            st.markdown(ai_reply)
    st.session_state.messages.append({"role": "assistant", "content": ai_reply})