import streamlit as st
import pandas as pd
import json
import os
from dotenv import load_dotenv
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- 0. é—¨å«ç³»ç»Ÿ ---
def check_access():
    if "authenticated" not in st.session_state:
        st.session_state.authenticated = False

    if st.session_state.authenticated:
        return True

    st.title("ğŸ”’ è¿™æ˜¯ä¸€ä¸ªç§å¯†åº”ç”¨")
    st.write("è¯·åœ¨ä¸‹æ–¹è¾“å…¥é‚€è¯·ç ä»¥ç»§ç»­è®¿é—®ã€‚")
    
    user_input = st.text_input("è¯·è¾“å…¥é‚€è¯·ç  (Access Key)", type="password")
    
    if st.button("è§£é”è¿›å…¥"):
        valid_keys = st.secrets.get("access_keys", [])
        if user_input in valid_keys:
            st.session_state.authenticated = True
            st.success("âœ… éªŒè¯æˆåŠŸï¼æ­£åœ¨åŠ è½½...")
            st.rerun()
        else:
            st.error("âŒ é‚€è¯·ç æ— æ•ˆ")
    return False

if not check_access():
    st.stop()

# --- 1. é…ç½®åŠ è½½ ---
if "OPENAI_API_KEY" in st.secrets:
    API_KEY = st.secrets["OPENAI_API_KEY"]
    BASE_URL = st.secrets["OPENAI_BASE_URL"]
    MODEL_NAME = st.secrets["OPENAI_MODEL_NAME"]
else:
    load_dotenv()
    API_KEY = os.getenv("OPENAI_API_KEY")
    BASE_URL = os.getenv("OPENAI_BASE_URL")
    MODEL_NAME = os.getenv("OPENAI_MODEL_NAME")

if not API_KEY:
    st.error("âŒ æœªé…ç½® API Key")
    st.stop()

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
DATA_FILE = "punch_recipes.jsonl"

st.set_page_config(page_title="Punch AI ä¾é…’å¸ˆ", page_icon="ğŸ¸", layout="wide") 
# æ³¨æ„ï¼šlayout æ”¹ä¸º 'wide' å¯ä»¥è®©ä¾§è¾¹æ å’Œä¸»å†…å®¹æ›´å®½æ•

# --- 2. æ•°æ®åŠ è½½ä¸å‘é‡åŒ– (ä¿æŒ char_wb æ¨¡ç³Šæœç´¢) ---
@st.cache_resource
def load_data_and_vectors():
    data = []
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line))
    except FileNotFoundError:
        return None, None, None

    df = pd.DataFrame(data)

    # æ··åˆæ–‡æœ¬ç”¨äºæœç´¢
    df['combined_text'] = (
        df['title'].fillna('') + " " + 
        df['ingredients'].astype(str) + " " + 
        df['tags'].astype(str)
    )

    # ä½¿ç”¨å­—ç¬¦çº§ n-gram å®ç°æ¨¡ç³ŠåŒ¹é…
    vectorizer = TfidfVectorizer(
        stop_words='english',
        analyzer='char_wb', 
        ngram_range=(3, 5)
    )
    
    tfidf_matrix = vectorizer.fit_transform(df['combined_text'])

    return df, vectorizer, tfidf_matrix

df, vectorizer, tfidf_matrix = load_data_and_vectors()

if df is None:
    st.error(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ {DATA_FILE}")
    st.stop()

# --- 3. æ ¸å¿ƒ AI é€»è¾‘ ---
def get_ai_recommendation(user_query):
    # === A. æ£€ç´¢ ===
    try:
        user_vec = vectorizer.transform([user_query])
        similarities = cosine_similarity(user_vec, tfidf_matrix).flatten()
        top_indices = similarities.argsort()[-30:][::-1]
        candidates = df.iloc[top_indices]
    except Exception as e:
        return f"æ£€ç´¢ç³»ç»Ÿå‡ºé”™äº†: {e}", pd.DataFrame()

    # === B. å¢å¼º ===
    context_text = ""
    for idx, row in candidates.iterrows():
        context_text += f"""
        [é…’å: {row['title']}]
        [åŸæ–™: {row['ingredients']}]
        [æ­¥éª¤: {row['instructions']}]
        [ç®€ä»‹: {row['intro_philosophy'][:100]}]
        ---
        """

    # === C. ç”Ÿæˆ ===
    combined_prompt = f"""
    ã€è§’è‰²è®¾å®šã€‘
    ä½ æ˜¯ä¸€ä½ä¸–ç•Œçº§çš„é¸¡å°¾é…’ä¸“å®¶ã€‚
    
    ã€ä»»åŠ¡ã€‘
    æ ¹æ®é¡¾å®¢éœ€æ±‚ï¼š"{user_query}"
    ä»ä¸‹é¢çš„ã€å€™é€‰é…’å•ã€‘ä¸­æŒ‘é€‰ 3 æ¬¾æœ€åˆé€‚çš„é…æ–¹ã€‚
    
    ã€å€™é€‰é…’å•ã€‘
    {context_text}

    ã€å›å¤è¦æ±‚ã€‘
    1. å¿…é¡»ä¿ç•™å®Œæ•´çš„åŸæ–™ç”¨é‡å’Œæ­¥éª¤ã€‚
    2. ä¸­æ–‡å›ç­”ï¼Œä¼˜é›…ä¸“ä¸šã€‚
    3. æ ¼å¼ï¼š
       ### ğŸ¸ [é…’å]
       - **æ¨èç†ç”±**: ...
       - **åŸæ–™**: ...
       - **æ­¥éª¤**: ...
    """

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME, 
            messages=[{"role": "user", "content": combined_prompt}],
            temperature=0.7,
            max_tokens=4096, 
            presence_penalty=0.6
        )
        if not response.choices:
            return f"âš ï¸ API è¿”å›ç©ºç»“æœã€‚", candidates
        return response.choices[0].message.content, candidates

    except Exception as e:
        return f"âŒ AI è¿æ¥æŠ¥é”™: {str(e)}", pd.DataFrame()

# ==========================================
# ğŸ¨ ç•Œé¢å¸ƒå±€å¼€å§‹
# ==========================================

st.title("ğŸ¸ Punch AI ä¾é…’å¸ˆ")

# --- ğŸ” ä¾§è¾¹æ ï¼šè¶…çº§æ¨¡ç³Šæœç´¢ ---
with st.sidebar:
    st.header("ğŸ“– é…æ–¹ç™¾ç§‘å…¨ä¹¦")
    # 1. æœç´¢æ¡†
    search_query = st.text_input("ğŸ” æœç´¢é…æ–¹ (æ”¯æŒæ¨¡ç³Šæ‹¼å†™)", placeholder="ä¾‹å¦‚: Bronx æˆ– margrita")
    
    selected_recipe_id = None
    
    if search_query:
        # å¤ç”¨é‚£ä¸ªå¼ºå¤§çš„å‘é‡æœç´¢å¼•æ“
        # å³ä½¿ä½ è¾“é”™ "Mrgarita"ï¼Œå®ƒä¹Ÿèƒ½ç®—å‡ºå®ƒæ˜¯ Margarita
        search_vec = vectorizer.transform([search_query])
        sims = cosine_similarity(search_vec, tfidf_matrix).flatten()
        
        # æ‰¾å‡ºæœ€ç›¸ä¼¼çš„ 10 ä¸ª
        top_indices = sims.argsort()[-10:][::-1]
        
        # åˆ¶ä½œä¸‹æ‹‰èœå•é€‰é¡¹å­—å…¸: { "é…’å": ID }
        options_map = {}
        for i in top_indices:
            row = df.iloc[i]
            # å¦‚æœç›¸ä¼¼åº¦å¤ªä½(å°äº0.1)ï¼Œå¯èƒ½æ˜¯å™ªéŸ³ï¼Œä¸æ˜¾ç¤º
            if sims[i] > 0.1:
                options_map[f"{row['title']}"] = i
        
        if options_map:
            st.success(f"æ‰¾åˆ° {len(options_map)} ä¸ªç›¸å…³ç»“æœ:")
            # 2. ä¸‹æ‹‰é€‰æ‹©æ¡†
            selected_name = st.selectbox("ğŸ‘‡ ç‚¹å‡»é€‰æ‹©æŸ¥çœ‹è¯¦æƒ…:", list(options_map.keys()))
            
            if selected_name:
                selected_recipe_id = options_map[selected_name]
        else:
            st.warning("ğŸ¤” æœªæ‰¾åˆ°ç›¸ä¼¼é…æ–¹ï¼Œè¯·æ¢ä¸ªè¯è¯•è¯•")

# --- ğŸ“‹ ä¸»ç•Œé¢ï¼šå±•ç¤ºé…æ–¹è¯¦æƒ…å¡ç‰‡ (å¦‚æœæœ‰é€‰ä¸­) ---
if selected_recipe_id is not None:
    # è·å–é€‰ä¸­è¡Œçš„æ•°æ®
    recipe_data = df.iloc[selected_recipe_id]
    
    # æ¸²æŸ“å¡ç‰‡å®¹å™¨
    with st.container(border=True):
        col_close, col_title = st.columns([1, 8])
        with col_title:
            st.header(f"ğŸ¹ {recipe_data['title']}")
        
        # æ˜¾ç¤ºç®€ä»‹
        st.info(f"ğŸ’¡ {recipe_data['intro_philosophy']}")
        
        c1, c2 = st.columns(2)
        with c1:
            st.subheader("ğŸ§‚ åŸæ–™ Ingredients")
            # å¤„ç†åŸæ–™åˆ—è¡¨æ˜¾ç¤º
            ingredients_list = recipe_data['ingredients']
            if isinstance(ingredients_list, str):
                st.write(ingredients_list)
            elif isinstance(ingredients_list, list):
                for ing in ingredients_list:
                    st.markdown(f"- {ing}")
                    
        with c2:
            st.subheader("ğŸ¥£ åšæ³• Instructions")
            st.write(recipe_data['instructions'])
            
        st.caption(f"Tags: {recipe_data.get('tags', 'Classic')}")
        
    st.markdown("---") # åˆ†å‰²çº¿ï¼Œä¸‹é¢æ˜¯èŠå¤©åŒº

# --- ğŸ’¬ èŠå¤©åŒºåŸŸ (AI ä¾é…’å¸ˆ) ---
st.caption(f"ç§äººå®šåˆ¶ Â· {MODEL_NAME}")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "æ‚¨å¥½ï¼æ‚¨å¯ä»¥åœ¨å·¦ä¾§æœç´¢ç‰¹å®šçš„é…æ–¹å¡ç‰‡ï¼Œä¹Ÿå¯ä»¥ç›´æ¥åœ¨è¿™é‡Œå‘Šè¯‰æˆ‘æ‚¨çš„å£å‘³ï¼Œè®©æˆ‘ä¸ºæ‚¨æ¨èã€‚"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("æè¿°æ‚¨çš„å£å‘³ï¼Œæˆ–è®© AI æ¨è..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    with st.chat_message("assistant"):
        with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
            ai_reply, related = get_ai_recommendation(prompt)
            st.markdown(ai_reply)
    st.session_state.messages.append({"role": "assistant", "content": ai_reply})