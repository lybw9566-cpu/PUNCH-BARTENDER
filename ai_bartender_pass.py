import streamlit as st
import pandas as pd
import json
import os
from dotenv import load_dotenv
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- 0. é—¨å«ç³»ç»Ÿ (æ ¸å¿ƒä¿®æ”¹éƒ¨åˆ†) ---
def check_access():
    """
    é—¨å«å‡½æ•°ï¼šå¦‚æœæ²¡æœ‰é€šè¿‡éªŒè¯ï¼Œå°±æ˜¾ç¤ºç™»å½•æ¡†å¹¶åœæ­¢è¿è¡Œåé¢çš„ä»£ç 
    """
    # åˆå§‹åŒ–éªŒè¯çŠ¶æ€
    if "authenticated" not in st.session_state:
        st.session_state.authenticated = False

    # å¦‚æœå·²ç»ç™»å½•æˆåŠŸï¼Œç›´æ¥æ”¾è¡Œ
    if st.session_state.authenticated:
        return True

    # å¦‚æœæ²¡ç™»å½•ï¼Œæ˜¾ç¤ºç™»å½•ç•Œé¢
    st.title("ğŸ”’ è¿™æ˜¯ä¸€ä¸ªç§å¯†åº”ç”¨")
    st.write("è¯·åœ¨ä¸‹æ–¹è¾“å…¥é‚€è¯·ç ä»¥ç»§ç»­è®¿é—®ã€‚")
    
    # è·å–ç”¨æˆ·è¾“å…¥
    user_input = st.text_input("è¯·è¾“å…¥é‚€è¯·ç  (Access Key)", type="password")
    
    if st.button("è§£é”è¿›å…¥"):
        # æ£€æŸ¥é‚€è¯·ç æ˜¯å¦åœ¨æˆ‘ä»¬çš„â€œç™½åå•â€é‡Œ
        # æ³¨æ„ï¼šæˆ‘ä»¬ä¼šæŠŠç™½åå•æ”¾åœ¨ st.secrets é‡Œ
        valid_keys = st.secrets.get("access_keys", [])
        
        if user_input in valid_keys:
            st.session_state.authenticated = True
            st.success("âœ… éªŒè¯æˆåŠŸï¼æ­£åœ¨åŠ è½½...")
            st.rerun() # åˆ·æ–°é¡µé¢è¿›å…¥ä¸»ç¨‹åº
        else:
            st.error("âŒ é‚€è¯·ç æ— æ•ˆæˆ–å·²å¤±æ•ˆ")
    
    # å¦‚æœæ²¡é€šè¿‡éªŒè¯ï¼Œè¿”å› Falseï¼Œé˜»æ­¢åç»­ä»£ç è¿è¡Œ
    return False

# æ‰§è¡Œé—¨å«æ£€æŸ¥
if not check_access():
    st.stop() # ğŸ›‘ åœæ­¢è¿è¡Œä¸‹é¢çš„æ‰€æœ‰ä»£ç 

# ===========================================
#  ä»¥ä¸‹æ˜¯åŸæœ¬çš„ AI ä¾é…’å¸ˆä»£ç  (åªæœ‰é€šè¿‡ä¸Šé¢æ£€æŸ¥æ‰ä¼šè¿è¡Œåˆ°è¿™é‡Œ)
# ===========================================

# --- 1. é…ç½®åŠ è½½ ---
# ä¼˜å…ˆä» Streamlit Cloud çš„ Secrets è¯»å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¯»å–æœ¬åœ° .env
if "OPENAI_API_KEY" in st.secrets:
    API_KEY = st.secrets["OPENAI_API_KEY"]
    BASE_URL = st.secrets["OPENAI_BASE_URL"]
    MODEL_NAME = st.secrets["OPENAI_MODEL_NAME"]
else:
    load_dotenv()
    API_KEY = os.getenv("OPENAI_API_KEY")
    BASE_URL = os.getenv("OPENAI_BASE_URL")
    MODEL_NAME = os.getenv("OPENAI_MODEL_NAME")

if not API_KEY:
    st.error("âŒ æœªé…ç½® API Key")
    st.stop()

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
DATA_FILE = "punch_recipes.jsonl"

# ... (ä¿æŒåŸæœ¬çš„ Page Config) ...
# æ³¨æ„ï¼šset_page_config å¿…é¡»æ˜¯ Streamlit å‘½ä»¤çš„ç¬¬ä¸€è¡Œï¼Œ
# ä½†ä¸ºäº†é…åˆé—¨å«é€»è¾‘ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒç§»åˆ°æœ€æœ€ä¸Šé¢ï¼Œæˆ–è€…æ¥å—è¿™é‡Œçš„å°è­¦å‘Šã€‚
# ä¸ºäº†ä»£ç è§„èŒƒï¼Œå»ºè®®æŠŠ st.set_page_config ç§»åˆ°ä»£ç æ–‡ä»¶çš„ç¬¬ä¸€è¡Œï¼ˆimport ä¹‹åï¼‰ã€‚
# è¿™é‡Œä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œå…ˆä¸ç§»åŠ¨ï¼ŒStreamlit å¯èƒ½ä¼šæŠ¥ä¸ªæ— å®³çš„ Warningã€‚

# --- 2. æ•°æ®åŠ è½½ä¸å‘é‡åŒ– (ä¿æŒä¸å˜) ---
@st.cache_resource
def load_data_and_vectors():
    data = []
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line))
    except FileNotFoundError:
        return None, None, None

    df = pd.DataFrame(data)
    df['combined_text'] = (
        df['title'].fillna('') + " " + 
        df['intro_philosophy'].fillna('') + " " + 
        df['ingredients'].astype(str) + " " + 
        df['tags'].astype(str)
    )
    vectorizer = TfidfVectorizer(stop_words='english')
    tfidf_matrix = vectorizer.fit_transform(df['combined_text'])
    return df, vectorizer, tfidf_matrix

df, vectorizer, tfidf_matrix = load_data_and_vectors()

if df is None:
    st.error(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ {DATA_FILE}")
    st.stop()

# --- 3. æ ¸å¿ƒé€»è¾‘ (GPT é€šç”¨ç‰ˆ) ---
def get_ai_recommendation(user_query):
    # === A. æ£€ç´¢ ===
    try:
        user_vec = vectorizer.transform([user_query])
        similarities = cosine_similarity(user_vec, tfidf_matrix).flatten()
        top_indices = similarities.argsort()[-15:][::-1]
        candidates = df.iloc[top_indices]
    except Exception as e:
        return f"æ£€ç´¢ç³»ç»Ÿå‡ºé”™äº†: {e}", pd.DataFrame()

    # === B. å¢å¼º ===
    context_text = ""
    for idx, row in candidates.iterrows():
        context_text += f"""
        [é…’å: {row['title']}]
        [åŸæ–™: {row['ingredients']}]
        [æ­¥éª¤: {row['instructions']}]
        [ç®€ä»‹: {row['intro_philosophy'][:100]}]
        ---
        """

    # === C. ç”Ÿæˆ ===
    combined_prompt = f"""
    ã€è§’è‰²è®¾å®šã€‘
    ä½ æ˜¯ä¸€ä½ä¸–ç•Œçº§çš„é¸¡å°¾é…’ä¸“å®¶ã€‚
    
    ã€ä»»åŠ¡ã€‘
    æ ¹æ®é¡¾å®¢éœ€æ±‚ï¼š"{user_query}"
    ä»ä¸‹é¢çš„ã€å€™é€‰é…’å•ã€‘ä¸­æŒ‘é€‰ 3 æ¬¾æœ€åˆé€‚çš„é…æ–¹ã€‚
    
    ã€å€™é€‰é…’å•ã€‘
    {context_text}

    ã€å›å¤è¦æ±‚ã€‘
    1. å¿…é¡»ä¿ç•™å®Œæ•´çš„åŸæ–™ç”¨é‡å’Œæ­¥éª¤ã€‚
    2. ä¸­æ–‡å›ç­”ï¼Œä¼˜é›…ä¸“ä¸šã€‚
    3. æ ¼å¼ï¼š
       ### ğŸ¸ [é…’å]
       - **æ¨èç†ç”±**: ...
       - **åŸæ–™**: ...
       - **æ­¥éª¤**: ...
    """

    try:
        print(f"æ­£åœ¨è¯·æ±‚æ¨¡å‹: {MODEL_NAME}")
        
        response = client.chat.completions.create(
            model=MODEL_NAME, 
            messages=[
                {"role": "user", "content": combined_prompt}
            ],
            temperature=0.7,
            max_tokens=4096, 
            presence_penalty=0.6
            # ğŸ”´ æ³¨æ„ï¼šæˆ‘åˆ é™¤äº† extra_body å‚æ•°ï¼Œå› ä¸º GPT ä¸éœ€è¦å®ƒï¼Œä¹Ÿä¸ä¼šæ‹¦æˆªé…’ç²¾å†…å®¹ã€‚
        )
        
        if not response.choices:
            return f"âš ï¸ API è¿”å›ç©ºç»“æœã€‚è¯·æ£€æŸ¥ Secrets ä¸­çš„æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡® (æ¨è gpt-4o-mini)ã€‚", candidates
            
        return response.choices[0].message.content, candidates

    except Exception as e:
        return f"âŒ AI è¿æ¥æŠ¥é”™: {str(e)}", pd.DataFrame()
# --- 4. ç•Œé¢ UI (ä¿æŒä¸å˜) ---
# è¿™é‡Œä¸ºäº†ç¾è§‚ï¼Œæˆ‘ä»¬é‡æ–°æ˜¾ç¤ºä¸€ä¸‹ Titleï¼Œå› ä¸ºç™»å½•æˆåŠŸåæ‰å±•ç¤ºä¸»ç•Œé¢
st.title("ğŸ¸ Punch AI ä¾é…’å¸ˆ")
st.caption(f"ç§äººå®šåˆ¶ Â· {MODEL_NAME}")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ‚¨çš„ç§äººä¾é…’å¸ˆã€‚ç”±äºè¿™æ˜¯ç§äººæœåŠ¡å™¨ï¼Œæ„Ÿè°¢æ‚¨çš„é‚€è¯·ç éªŒè¯ã€‚\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³å–ç‚¹ä»€ä¹ˆï¼Ÿ"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("æè¿°æ‚¨çš„å£å‘³..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    with st.chat_message("assistant"):
        with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
            ai_reply, related = get_ai_recommendation(prompt)
            st.markdown(ai_reply)
    st.session_state.messages.append({"role": "assistant", "content": ai_reply})