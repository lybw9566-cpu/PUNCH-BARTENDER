import streamlit as st
import pandas as pd
import json
import os
from dotenv import load_dotenv
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- 0. é—¨å«ç³»ç»Ÿ (æ ¸å¿ƒä¿®æ”¹éƒ¨åˆ†) ---
def check_access():
    """
    é—¨å«å‡½æ•°ï¼šå¦‚æœæ²¡æœ‰é€šè¿‡éªŒè¯ï¼Œå°±æ˜¾ç¤ºç™»å½•æ¡†å¹¶åœæ­¢è¿è¡Œåé¢çš„ä»£ç 
    """
    # åˆå§‹åŒ–éªŒè¯çŠ¶æ€
    if "authenticated" not in st.session_state:
        st.session_state.authenticated = False

    # å¦‚æœå·²ç»ç™»å½•æˆåŠŸï¼Œç›´æ¥æ”¾è¡Œ
    if st.session_state.authenticated:
        return True

    # å¦‚æœæ²¡ç™»å½•ï¼Œæ˜¾ç¤ºç™»å½•ç•Œé¢
    st.title("ğŸ”’ è¿™æ˜¯ä¸€ä¸ªç§å¯†åº”ç”¨")
    st.write("è¯·åœ¨ä¸‹æ–¹è¾“å…¥é‚€è¯·ç ä»¥ç»§ç»­è®¿é—®ã€‚")
    
    # è·å–ç”¨æˆ·è¾“å…¥
    user_input = st.text_input("è¯·è¾“å…¥é‚€è¯·ç  (Access Key)", type="password")
    
    if st.button("è§£é”è¿›å…¥"):
        # æ£€æŸ¥é‚€è¯·ç æ˜¯å¦åœ¨æˆ‘ä»¬çš„â€œç™½åå•â€é‡Œ
        # æ³¨æ„ï¼šæˆ‘ä»¬ä¼šæŠŠç™½åå•æ”¾åœ¨ st.secrets é‡Œ
        valid_keys = st.secrets.get("access_keys", [])
        
        if user_input in valid_keys:
            st.session_state.authenticated = True
            st.success("âœ… éªŒè¯æˆåŠŸï¼æ­£åœ¨åŠ è½½...")
            st.rerun() # åˆ·æ–°é¡µé¢è¿›å…¥ä¸»ç¨‹åº
        else:
            st.error("âŒ é‚€è¯·ç æ— æ•ˆæˆ–å·²å¤±æ•ˆ")
    
    # å¦‚æœæ²¡é€šè¿‡éªŒè¯ï¼Œè¿”å› Falseï¼Œé˜»æ­¢åç»­ä»£ç è¿è¡Œ
    return False

# æ‰§è¡Œé—¨å«æ£€æŸ¥
if not check_access():
    st.stop() # ğŸ›‘ åœæ­¢è¿è¡Œä¸‹é¢çš„æ‰€æœ‰ä»£ç 

# ===========================================
#  ä»¥ä¸‹æ˜¯åŸæœ¬çš„ AI ä¾é…’å¸ˆä»£ç  (åªæœ‰é€šè¿‡ä¸Šé¢æ£€æŸ¥æ‰ä¼šè¿è¡Œåˆ°è¿™é‡Œ)
# ===========================================

# --- 1. é…ç½®åŠ è½½ ---
# ä¼˜å…ˆä» Streamlit Cloud çš„ Secrets è¯»å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¯»å–æœ¬åœ° .env
if "OPENAI_API_KEY" in st.secrets:
    API_KEY = st.secrets["OPENAI_API_KEY"]
    BASE_URL = st.secrets["OPENAI_BASE_URL"]
    MODEL_NAME = st.secrets["OPENAI_MODEL_NAME"]
else:
    load_dotenv()
    API_KEY = os.getenv("OPENAI_API_KEY")
    BASE_URL = os.getenv("OPENAI_BASE_URL")
    MODEL_NAME = os.getenv("OPENAI_MODEL_NAME")

if not API_KEY:
    st.error("âŒ æœªé…ç½® API Key")
    st.stop()

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
DATA_FILE = "punch_recipes.jsonl"

# ... (ä¿æŒåŸæœ¬çš„ Page Config) ...
# æ³¨æ„ï¼šset_page_config å¿…é¡»æ˜¯ Streamlit å‘½ä»¤çš„ç¬¬ä¸€è¡Œï¼Œ
# ä½†ä¸ºäº†é…åˆé—¨å«é€»è¾‘ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒç§»åˆ°æœ€æœ€ä¸Šé¢ï¼Œæˆ–è€…æ¥å—è¿™é‡Œçš„å°è­¦å‘Šã€‚
# ä¸ºäº†ä»£ç è§„èŒƒï¼Œå»ºè®®æŠŠ st.set_page_config ç§»åˆ°ä»£ç æ–‡ä»¶çš„ç¬¬ä¸€è¡Œï¼ˆimport ä¹‹åï¼‰ã€‚
# è¿™é‡Œä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œå…ˆä¸ç§»åŠ¨ï¼ŒStreamlit å¯èƒ½ä¼šæŠ¥ä¸ªæ— å®³çš„ Warningã€‚

# --- 2. æ•°æ®åŠ è½½ä¸å‘é‡åŒ– (å‡çº§ç‰ˆï¼šæ”¯æŒä¸­è‹±æ··åˆæœç´¢) ---
@st.cache_resource
def load_data_and_vectors():
    data = []
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line))
    except FileNotFoundError:
        return None, None, None

    df = pd.DataFrame(data)

    # æ··åˆæ–‡æœ¬ç”¨äºæœç´¢
    df['combined_text'] = (
        df['title'].fillna('') + " " + 
        df['ingredients'].astype(str) + " " + 
        df['tags'].astype(str)
        # ç§»é™¤äº†ç®€ä»‹ï¼Œå› ä¸ºç®€ä»‹å­—æ•°å¤ªå¤šä¼šç¨€é‡Šé…’åçš„æƒé‡ï¼Œå¯¼è‡´æœç´¢ä¸å‡†
    )

    # ğŸ”´ æ ¸å¿ƒå‡çº§ï¼šæ”¹ä¸º char_wb æ¨¡å¼ (å­—ç¬¦çº§ n-gram)
    # è¿™èƒ½è§£å†³ "æˆ‘æƒ³å–Bronx" è¿åœ¨ä¸€èµ·æœä¸åˆ°çš„é—®é¢˜ï¼Œä¹Ÿèƒ½å®¹å¿æ‹¼å†™é”™è¯¯
    vectorizer = TfidfVectorizer(
        stop_words='english',
        analyzer='char_wb',  # æŒ‰å­—æ¯åˆ‡åˆ†ï¼Œè€Œä¸æ˜¯æŒ‰å•è¯åˆ‡åˆ†
        ngram_range=(3, 5)   # æœç´¢ 3 åˆ° 5 ä¸ªå­—æ¯çš„ç»„åˆ
    )
    
    tfidf_matrix = vectorizer.fit_transform(df['combined_text'])

    return df, vectorizer, tfidf_matrix

# --- 3. æ ¸å¿ƒé€»è¾‘ (Gemini å¼ºåŠ›æŠ—å¹²æ‰°ç‰ˆ) ---
def get_ai_recommendation(user_query):
    # === A. æ£€ç´¢ ===
    try:
        user_vec = vectorizer.transform([user_query])
        similarities = cosine_similarity(user_vec, tfidf_matrix).flatten()
        
        # ğŸ”´ ä¿®æ”¹ç‚¹ï¼šå°† 15 æ”¹ä¸º 30ï¼Œæ‰©å¤§æœç´¢åœˆ
        top_indices = similarities.argsort()[-30:][::-1] 
        candidates = df.iloc[top_indices]

# === B. å¢å¼º (å…³é”®ä¿®æ”¹ç‚¹1ï¼šç¡®ä¿ä¼ å…¥æ­¥éª¤å’Œå®Œæ•´åŸæ–™) ===
    context_text = ""
    for idx, row in candidates.iterrows():
        # è¿™é‡Œæˆ‘ä»¬å°†åŸæ–™å’Œæ­¥éª¤éƒ½å®Œæ•´æ‹¼æ¥åˆ°ä¸Šä¸‹æ–‡é‡Œ
        context_text += f"""
        [ID: {idx}]
        é…’å: {row['title']}
        åŸæ–™åˆ—è¡¨(åŒ…å«ç”¨é‡): {row['ingredients']}
        åˆ¶ä½œæ­¥éª¤: {row['instructions']}
        ç®€ä»‹: {row['intro_philosophy'][:200]}...
        ---
        """

    # === C. ç”Ÿæˆ ===
    # ä¿®æ”¹ Promptï¼Œè¯•å›¾â€œæ¬ºéª—â€AI è¿™åªæ˜¯ç§‘å­¦ç ”ç©¶ï¼Œä¸æ˜¯å–é…’å»ºè®®ï¼Œé™ä½é£æ§æ¦‚ç‡
    combined_prompt = f"""
    ã€æŒ‡ä»¤ã€‘
    ä½ æ˜¯ä¸€ä½é¸¡å°¾é…’å†å²å­¦å®¶ã€‚è¯·å®¢è§‚åœ°åˆ†æä»¥ä¸‹é…æ–¹æ•°æ®ã€‚
    
    ã€ä»»åŠ¡ã€‘
    ç”¨æˆ·æŸ¥è¯¢ï¼š"{user_query}"
    åŸºäºã€å€™é€‰æ•°æ®ã€‘æå– 3 ä¸ªç›¸å…³æ¡ç›®ã€‚
    
    ã€å€™é€‰æ•°æ®ã€‘
    {context_text}

    ã€è¾“å‡ºè¦æ±‚ã€‘
    1. è¿™æ˜¯ç”¨äºæ•°æ®åº“å½’æ¡£çš„å®¢è§‚æè¿°ï¼Œè¯·ä¿ç•™å®Œæ•´åŸæ–™ç”¨é‡å’Œæ­¥éª¤ã€‚
    2. ä½¿ç”¨ä¸­æ–‡ã€‚
    3. æ ¼å¼ï¼š
       ### ğŸ¸ [é…’å]
       - **æ¨èç†ç”±**: ...
       - **åŸæ–™**: ...
       - **æ­¥éª¤**: ...
    """

    try:
        print(f"æ­£åœ¨è¯·æ±‚æ¨¡å‹: {MODEL_NAME}")
        
        response = client.chat.completions.create(
            model=MODEL_NAME, 
            messages=[
                {"role": "user", "content": combined_prompt}
            ],
            temperature=0.7,
            max_tokens=4096,
            presence_penalty=0.6,
            
            # ğŸ”´ æ ¸å¿ƒé˜²å¾¡ï¼šè¯•å›¾é€šè¿‡å‚æ•°å¼ºåˆ¶å…³é—­ Gemini çš„å®‰å…¨å®¡æŸ¥
            extra_body={
                "safetySettings": [
                    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
                ]
            }
        )
        
        # ğŸ›¡ï¸ é˜²å´©æºƒæŠ¤ç›¾ï¼šå¦‚æœ API è¿”å›ç©º (è¢«é£æ§æ‹¦æˆª)ï¼Œè¿™é‡Œæ¥ä½ï¼Œä¸è®©å®ƒæŠ¥é”™
        if not response.choices:
            return f"""
            âš ï¸ **ç”Ÿæˆå¤±è´¥ (è¢«é£æ§æ‹¦æˆª)**
            
            åŸå› ï¼šæ‚¨ä½¿ç”¨çš„ Gemini æ¨¡å‹åœ¨äº‘ç«¯æœåŠ¡å™¨ä¸Šè§¦å‘äº†è°·æ­Œçš„â€œé…’ç²¾å†…å®¹å®¡æŸ¥â€ã€‚
            
            **æœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼š**
            è¯·å» Streamlit Secretsï¼Œå°†æ¨¡å‹åå­—æ”¹ä¸ºï¼š**gpt-4o-mini**
            (è¿™ä¸ªæ¨¡å‹æ¯” GPT-4o ä¾¿å®œå¾ˆå¤šï¼Œä¸”é€šå¸¸æ‰€æœ‰åˆ†ç»„éƒ½æœ‰æƒé™ï¼Œä¹Ÿä¸ä¼šæ‹¦æˆªé…’ç²¾å†…å®¹)
            """, candidates
            
        return response.choices[0].message.content, candidates

    except Exception as e:
        return f"âŒ AI è¿æ¥æŠ¥é”™: {str(e)}", pd.DataFrame()
# --- 4. ç•Œé¢ UI (ä¿æŒä¸å˜) ---
# è¿™é‡Œä¸ºäº†ç¾è§‚ï¼Œæˆ‘ä»¬é‡æ–°æ˜¾ç¤ºä¸€ä¸‹ Titleï¼Œå› ä¸ºç™»å½•æˆåŠŸåæ‰å±•ç¤ºä¸»ç•Œé¢
st.title("ğŸ¸ Punch AI ä¾é…’å¸ˆ")
st.caption(f"ç§äººå®šåˆ¶ Â· {MODEL_NAME}")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ‚¨çš„ç§äººä¾é…’å¸ˆã€‚ç”±äºè¿™æ˜¯ç§äººæœåŠ¡å™¨ï¼Œæ„Ÿè°¢æ‚¨çš„é‚€è¯·ç éªŒè¯ã€‚\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³å–ç‚¹ä»€ä¹ˆï¼Ÿ"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("æè¿°æ‚¨çš„å£å‘³..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    with st.chat_message("assistant"):
        with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
            ai_reply, related = get_ai_recommendation(prompt)
            st.markdown(ai_reply)
    st.session_state.messages.append({"role": "assistant", "content": ai_reply})

    # ... (å‰é¢çš„ä»£ç ä¿æŒä¸å˜) ...

# === ğŸ› ï¸ æ–°å¢ï¼šä¾§è¾¹æ æ•°æ®åº“è‡ªæ£€å·¥å…· ===
with st.sidebar:
    st.header("ğŸ” æ•°æ®åº“è‡ªæ£€")
    check_query = st.text_input("è¾“å…¥é…’åæ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨", placeholder="ä¾‹å¦‚: Bronx")
    
    if check_query:
        # ç®€å•çš„æ–‡æœ¬åŒ¹é…ï¼Œä¸èµ°å‘é‡æœç´¢
        found = df[df['title'].str.contains(check_query, case=False, na=False)]
        
        if not found.empty:
            st.success(f"âœ… æ‰¾åˆ°äº† {len(found)} æ¡è®°å½•ï¼")
            for i, row in found.iterrows():
                st.write(f"ID: {i} | {row['title']}")
        else:
            st.error("âŒ æ•°æ®åº“é‡ŒçœŸçš„æ²¡æœ‰...")
            st.caption(f"å½“å‰åŠ è½½çš„æ•°æ®æ€»é‡: {len(df)} æ¡")